{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a24649df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\Admin\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\Admin\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tf-keras in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.20.1)\n",
      "Requirement already satisfied: tensorflow<2.21,>=2.20 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tf-keras) (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (24.1)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (74.1.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.68.1)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.11.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.12.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.5.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.20->tf-keras) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (13.8.1)\n",
      "Requirement already satisfied: namex in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.7)\n",
      "Requirement already satisfied: pillow in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (10.4.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow-intel (C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\Admin\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain langchain-community python-dotenv chromadb sentence-transformers\n",
    "%pip install pypdf -q\n",
    "%pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50e0cbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('RAG_TECHNIQUES')\n",
    "\n",
    "import os\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.chains import RetrievalQA\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5612ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helper_functions defined\n"
     ]
    }
   ],
   "source": [
    "# Definition of helper_functions content\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "def read_pdf_to_string(file_path: str) -> str:\n",
    "    \"\"\"Reads a PDF file and returns its content as a single string.\"\"\"\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    docs = loader.load()\n",
    "    return \"\".join([doc.page_content for doc in docs])\n",
    "\n",
    "def encode_from_string(text_content: str) -> Chroma:\n",
    "    \"\"\"Encodes text content and creates a Chroma vector store.\"\"\"\n",
    "    embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    # Split text content into chunks to avoid exceeding embedding model limits or context window\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    texts = text_splitter.create_documents([text_content])\n",
    "    db = Chroma.from_documents(texts, embeddings)\n",
    "    return db\n",
    "\n",
    "print(\"helper_functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceb85c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\" #Intels Library\n",
    "os.makedirs('data', exist_ok=True)\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af12f55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama 3.2 initialized!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13476\\3148274586.py:1: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"llama3.2:1b\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(\"Llama 3.2 initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0724f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF selection function ready!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def select_and_process_pdf():\n",
    "    \"\"\"\n",
    "    Returns the fixed path to the Cyclone Emission Control PDF.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"USING DEFAULT PDF FILE\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Define your fixed path here\n",
    "    pdf_path = os.path.abspath(\"data/Cyclone_Emission_Control.pdf\")\n",
    "\n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(f\"⚠️ File not found at: {pdf_path}\")\n",
    "    else:\n",
    "        print(f\"✓ Using PDF: {pdf_path}\")\n",
    "\n",
    "    return pdf_path\n",
    "\n",
    "print(\"PDF selection function ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72bebe6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization function ready!\n"
     ]
    }
   ],
   "source": [
    "def initialize_rag_system(pdf_path: str = None):\n",
    "    \"\"\"\n",
    "    Initialize the RAG system with a specified or selected PDF.\n",
    "\n",
    "    Args:\n",
    "        pdf_path: Optional path to PDF. If None, user will be prompted to upload.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (qa_chain, retriever, content, pdf_path)\n",
    "    \"\"\"\n",
    "    # Get PDF path\n",
    "    if pdf_path is None:\n",
    "        pdf_path = select_and_process_pdf()\n",
    "\n",
    "    print(f\"\\n[Processing] Reading PDF: {pdf_path}\")\n",
    "\n",
    "    # Load and process document\n",
    "    content = read_pdf_to_string(pdf_path)\n",
    "    print(f\"✓ PDF loaded: {len(content)} characters\")\n",
    "\n",
    "    print(\"[Processing] Creating vector embeddings...\")\n",
    "    vectorstore = encode_from_string(content)\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "    print(\"✓ Vector store created\")\n",
    "\n",
    "    # Create QA chain\n",
    "    print(\"[Processing] Initializing QA chain...\")\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True\n",
    "    )\n",
    "    print(\"✓ RAG system ready!\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    return qa_chain, retriever, content, pdf_path\n",
    "\n",
    "print(\"Initialization function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3abfec3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedback management functions ready!\n"
     ]
    }
   ],
   "source": [
    "def get_user_feedback(query: str, response: str, relevance: int, quality: int, comments: str = \"\") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Create a feedback entry.\n",
    "\n",
    "    Args:\n",
    "        query: The user's query\n",
    "        response: The system's response\n",
    "        relevance: Relevance score (1-5)\n",
    "        quality: Quality score (1-5)\n",
    "        comments: Optional comments\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"response\": response,\n",
    "        \"relevance\": int(relevance),\n",
    "        \"quality\": int(quality),\n",
    "        \"comments\": comments\n",
    "    }\n",
    "\n",
    "def store_feedback(feedback: Dict[str, Any], filepath: str = \"data/feedback_data.json\"):\n",
    "    \"\"\"Store feedback to JSON file.\"\"\"\n",
    "    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "\n",
    "    # Read existing data\n",
    "    existing_data = []\n",
    "    if os.path.exists(filepath):\n",
    "        try:\n",
    "            with open(filepath, \"r\") as f:\n",
    "                content = f.read().strip()\n",
    "                if content:\n",
    "                    # Handle both line-delimited and array formats\n",
    "                    if content.startswith('['):\n",
    "                        existing_data = json.loads(content)\n",
    "                    else:\n",
    "                        for line in content.split('\\n'):\n",
    "                            if line.strip():\n",
    "                                existing_data.append(json.loads(line))\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Warning: Could not parse existing feedback file. Starting fresh.\")\n",
    "            existing_data = []\n",
    "\n",
    "    # Append new feedback\n",
    "    existing_data.append(feedback)\n",
    "\n",
    "    # Write back as proper JSON array\n",
    "    with open(filepath, \"w\") as f:\n",
    "        json.dump(existing_data, f, indent=2)\n",
    "\n",
    "    print(f\"✓ Feedback stored successfully. Total feedback entries: {len(existing_data)}\")\n",
    "\n",
    "def load_feedback_data(filepath: str = \"data/feedback_data.json\") -> List[Dict[str, Any]]:\n",
    "    \"\"\"Load feedback data from JSON file.\"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        print(\"No feedback data file found. Starting with empty feedback.\")\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        with open(filepath, \"r\") as f:\n",
    "            content = f.read().strip()\n",
    "            if not content:\n",
    "                return []\n",
    "\n",
    "            # Handle both line-delimited and array formats\n",
    "            if content.startswith('['):\n",
    "                return json.loads(content)\n",
    "            else:\n",
    "                feedback_data = []\n",
    "                for line in content.split('\\n'):\n",
    "                    if line.strip():\n",
    "                        feedback_data.append(json.loads(line))\n",
    "                return feedback_data\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error loading feedback data: {e}\")\n",
    "        return []\n",
    "\n",
    "print(\"Feedback management functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c914714e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance adjustment functions ready!\n"
     ]
    }
   ],
   "source": [
    "def check_relevance_with_llm(query: str, feedback_query: str, doc_content: str, feedback_response: str, llm) -> bool:\n",
    "    \"\"\"\n",
    "    Use LLM to check if feedback is relevant to current query and document.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if relevant, False otherwise\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"You are an expert at determining relevance between queries and documents.\n",
    "\n",
    "Current Query: {query}\n",
    "Feedback Query: {feedback_query}\n",
    "Document Content (first 500 chars): {doc_content[:500]}\n",
    "Feedback Response (first 300 chars): {feedback_response[:300]}\n",
    "\n",
    "Task: Determine if the feedback response is relevant to BOTH:\n",
    "1. The current query topic\n",
    "2. The document content\n",
    "\n",
    "Consider semantic similarity, not just exact word matches.\n",
    "\n",
    "Respond with ONLY 'Yes' or 'No'.\n",
    "Answer:\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = llm.invoke(prompt)\n",
    "        answer_text = response.content.strip().lower() if hasattr(response, 'content') else str(response).strip().lower()\n",
    "        return 'yes' in answer_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error in relevance checking: {e}\")\n",
    "        return False\n",
    "\n",
    "def adjust_relevance_scores(query: str, docs: List[Any], feedback_data: List[Dict[str, Any]], llm) -> List[Any]:\n",
    "    \"\"\"\n",
    "    Adjust document relevance scores based on historical feedback.\n",
    "\n",
    "    Args:\n",
    "        query: Current user query\n",
    "        docs: Retrieved documents\n",
    "        feedback_data: Historical feedback data\n",
    "        llm: Language model for relevance checking\n",
    "\n",
    "    Returns:\n",
    "        List of documents sorted by adjusted relevance scores\n",
    "    \"\"\"\n",
    "    if not feedback_data:\n",
    "        print(\"No feedback data available for adjustment.\")\n",
    "        return docs\n",
    "\n",
    "    print(f\"Adjusting relevance scores using {len(feedback_data)} feedback entries...\")\n",
    "\n",
    "    for doc in docs:\n",
    "        # Initialize relevance score if not present\n",
    "        if 'relevance_score' not in doc.metadata:\n",
    "            doc.metadata['relevance_score'] = 1.0\n",
    "\n",
    "        relevant_feedback_count = 0\n",
    "        total_relevance = 0\n",
    "\n",
    "        for feedback in feedback_data:\n",
    "            # Use LLM to check if this feedback is relevant\n",
    "            is_relevant = check_relevance_with_llm(\n",
    "                query=query,\n",
    "                feedback_query=feedback['query'],\n",
    "                doc_content=doc.page_content,\n",
    "                feedback_response=feedback['response'],\n",
    "                llm=llm\n",
    "            )\n",
    "\n",
    "            if is_relevant:\n",
    "                relevant_feedback_count += 1\n",
    "                total_relevance += feedback['relevance']\n",
    "\n",
    "        # Adjust score based on relevant feedback\n",
    "        if relevant_feedback_count > 0:\n",
    "            avg_relevance = total_relevance / relevant_feedback_count\n",
    "            # Normalize to -1 to 1 scale (3 is neutral on 1-5 scale)\n",
    "            adjustment_factor = (avg_relevance - 3) / 2\n",
    "            doc.metadata['relevance_score'] *= (1 + adjustment_factor * 0.3)  # 30% max adjustment\n",
    "            print(f\"  Document adjusted: {relevant_feedback_count} relevant feedback, avg score: {avg_relevance:.2f}\")\n",
    "\n",
    "    # Sort by adjusted scores\n",
    "    sorted_docs = sorted(docs, key=lambda x: x.metadata.get('relevance_score', 1.0), reverse=True)\n",
    "    return sorted_docs\n",
    "\n",
    "print(\"Relevance adjustment functions ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b12ddc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Index fine-tuning function ready!\n"
     ]
    }
   ],
   "source": [
    "def fine_tune_index(feedback_data: List[Dict[str, Any]], original_content: str) -> Any:\n",
    "    \"\"\"\n",
    "    Create an enhanced index incorporating high-quality feedback.\n",
    "\n",
    "    Args:\n",
    "        feedback_data: Historical feedback data\n",
    "        original_content: Original document content\n",
    "\n",
    "    Returns:\n",
    "        New vectorstore with enhanced content\n",
    "    \"\"\"\n",
    "    if not feedback_data:\n",
    "        print(\"No feedback data available for fine-tuning.\")\n",
    "        return encode_from_string(original_content)\n",
    "\n",
    "    # Filter high-quality responses (relevance >= 4 AND quality >= 4)\n",
    "    good_responses = [\n",
    "        f for f in feedback_data\n",
    "        if f.get('relevance', 0) >= 4 and f.get('quality', 0) >= 4\n",
    "    ]\n",
    "\n",
    "    print(f\"Fine-tuning index with {len(good_responses)} high-quality responses...\")\n",
    "\n",
    "    if not good_responses:\n",
    "        print(\"No high-quality responses found. Using original content only.\")\n",
    "        return encode_from_string(original_content)\n",
    "\n",
    "    # Create additional context from high-quality Q&A pairs\n",
    "    additional_texts = []\n",
    "    for f in good_responses:\n",
    "        # Format as Q&A pair for better semantic matching\n",
    "        qa_text = f\"Question: {f['query']}\\nAnswer: {f['response']}\"\n",
    "        additional_texts.append(qa_text)\n",
    "\n",
    "    # Combine all texts\n",
    "    combined_content = original_content + \"\\n\\n\" + \"\\n\\n\".join(additional_texts)\n",
    "\n",
    "    # Create new vectorstore\n",
    "    new_vectorstore = encode_from_string(combined_content)\n",
    "    print(f\"✓ Index fine-tuned with {len(additional_texts)} additional Q&A pairs\")\n",
    "\n",
    "    return new_vectorstore\n",
    "\n",
    "print(\" Index fine-tuning function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf1c52f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "USING DEFAULT PDF FILE\n",
      "================================================================================\n",
      "✓ Using PDF: c:\\Users\\Admin\\Desktop\\New folder\\data\\Cyclone_Emission_Control.pdf\n",
      "\n",
      "[Processing] Reading PDF: c:\\Users\\Admin\\Desktop\\New folder\\data\\Cyclone_Emission_Control.pdf\n",
      "✓ PDF loaded: 24644 characters\n",
      "[Processing] Creating vector embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_13476\\4130052877.py:14: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Vector store created\n",
      "[Processing] Initializing QA chain...\n",
      "✓ RAG system ready!\n",
      "================================================================================\n",
      "\n",
      " System initialized with: c:\\Users\\Admin\\Desktop\\New folder\\data\\Cyclone_Emission_Control.pdf\n"
     ]
    }
   ],
   "source": [
    "qa_chain, retriever, content, current_pdf = initialize_rag_system()\n",
    "\n",
    "print(f\"\\n System initialized with: {current_pdf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "209e7e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  What is the intended use of the Cyclone Separator according to the manual?\n",
      "\n",
      "Getting response...\n",
      "\n",
      " Answer:\n",
      "According to the manual, the Cyclone Separator is \"exclusively intended for the removal of solid particles contained in fumes given off by heat generators.\"\n"
     ]
    }
   ],
   "source": [
    "query = \" What is the intended use of the Cyclone Separator according to the manual?\"\n",
    "print(f\"Query: {query}\\n\")\n",
    "\n",
    "# Get response\n",
    "print(\"Getting response...\")\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "response = result[\"result\"]\n",
    "\n",
    "print(\"\\n Answer:\")\n",
    "print(response)\n",
    "\n",
    "# Store response for feedback\n",
    "current_query = query\n",
    "current_response = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fabd7f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Feedback stored successfully. Total feedback entries: 2\n",
      "\n",
      "Feedback recorded:\n",
      "  Relevance: 5/5\n",
      "  Quality: 4/5\n",
      "  Comments: Good explanation but could be more detailed\n"
     ]
    }
   ],
   "source": [
    "relevance = 5  \n",
    "quality = 4    \n",
    "comments = \"Good explanation but could be more detailed\"\n",
    "# Feedback Store\n",
    "feedback = get_user_feedback(current_query, current_response, relevance, quality, comments)\n",
    "store_feedback(feedback)\n",
    "\n",
    "print(f\"\\nFeedback recorded:\")\n",
    "print(f\"  Relevance: {relevance}/5\")\n",
    "print(f\"  Quality: {quality}/5\")\n",
    "print(f\"  Comments: {comments}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "137f7ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPLYING FEEDBACK TO IMPROVE SYSTEM\n",
      "\n",
      "Total feedback entries: 2\n",
      "\n",
      "Adjusting relevance scores...\n",
      "Adjusting relevance scores using 2 feedback entries...\n",
      "\n",
      "Top document (adjusted):\n",
      "  Content preview: Question:  What is the intended use of the Cyclone Separator according to the manual?\n",
      "Answer: According to the manual, the Cyclone Separator is \"exclu...\n",
      "  Relevance score: 1.0\n",
      "\n",
      "Fine-tuning index with high-quality feedback...\n",
      "Fine-tuning index with 2 high-quality responses...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Index fine-tuned with 2 additional Q&A pairs\n",
      "\n",
      " System updated with feedback!\n"
     ]
    }
   ],
   "source": [
    "print(\"APPLYING FEEDBACK TO IMPROVE SYSTEM\")\n",
    "\n",
    "all_feedback = load_feedback_data()\n",
    "print(f\"\\nTotal feedback entries: {len(all_feedback)}\")\n",
    "\n",
    "print(\"\\nAdjusting relevance scores...\")\n",
    "docs = retriever.get_relevant_documents(current_query)\n",
    "adjusted_docs = adjust_relevance_scores(current_query, docs, all_feedback, llm)\n",
    "\n",
    "print(f\"\\nTop document (adjusted):\")\n",
    "print(f\"  Content preview: {adjusted_docs[0].page_content[:150]}...\")\n",
    "print(f\"  Relevance score: {adjusted_docs[0].metadata.get('relevance_score', 'N/A')}\")\n",
    "\n",
    "print(\"\\nFine-tuning index with high-quality feedback...\")\n",
    "new_vectorstore = fine_tune_index(all_feedback, content)\n",
    "retriever = new_vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "# Create new QA chain with updated retriever\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "print(\"\\n System updated with feedback!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "383a233c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: Explain the principle of operation of the Cyclone Separator\n",
      "\n",
      " Getting response with updated system...\n",
      "\n",
      " Answer:\n",
      "I don't know. The manual doesn't mention a specific principle of operation for the Cyclone Separator. It only states that it is \"exclusively intended for the removal of solid particles contained in fumes given off by heat generators.\"\n"
     ]
    }
   ],
   "source": [
    "query2 = \"Explain the principle of operation of the Cyclone Separator\"\n",
    "print(f\"\\nQuery: {query2}\\n\")\n",
    "\n",
    "print(\" Getting response with updated system...\")\n",
    "result2 = qa_chain.invoke({\"query\": query2})\n",
    "response2 = result2[\"result\"]\n",
    "\n",
    "print(\"\\n Answer:\")\n",
    "print(response2)\n",
    "\n",
    "# Store for feedback\n",
    "current_query = query2\n",
    "current_response = response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14aa1ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEEDBACK STATISTICS\n",
      "\n",
      "Total feedback entries: 2\n",
      "Average relevance score: 5.00/5\n",
      "Average quality score: 4.00/5\n",
      "High-quality responses: 2\n",
      "\n",
      "All feedback entries:\n",
      "\n",
      "1. Query:  What is the intended use of the Cyclone Separator according to the manual?\n",
      "   Relevance: 5/5, Quality: 4/5\n",
      "   Comments: Good explanation but could be more detailed\n",
      "\n",
      "2. Query:  What is the intended use of the Cyclone Separator according to the manual?\n",
      "   Relevance: 5/5, Quality: 4/5\n",
      "   Comments: Good explanation but could be more detailed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feedback_data = load_feedback_data()\n",
    "\n",
    "print(\"FEEDBACK STATISTICS\")\n",
    "print(f\"\\nTotal feedback entries: {len(feedback_data)}\")\n",
    "\n",
    "if feedback_data:\n",
    "    avg_relevance = sum(f.get('relevance', 0) for f in feedback_data) / len(feedback_data)\n",
    "    avg_quality = sum(f.get('quality', 0) for f in feedback_data) / len(feedback_data)\n",
    "    print(f\"Average relevance score: {avg_relevance:.2f}/5\")\n",
    "    print(f\"Average quality score: {avg_quality:.2f}/5\")\n",
    "\n",
    "    high_quality = len([f for f in feedback_data if f.get('relevance', 0) >= 4 and f.get('quality', 0) >= 4])\n",
    "    print(f\"High-quality responses: {high_quality}\")\n",
    "\n",
    "    print(\"\\nAll feedback entries:\")\n",
    "    for i, f in enumerate(feedback_data, 1):\n",
    "        print(f\"\\n{i}. Query: {f['query']}\")\n",
    "        print(f\"   Relevance: {f['relevance']}/5, Quality: {f['quality']}/5\")\n",
    "        if f.get('comments'):\n",
    "            print(f\"   Comments: {f['comments']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66dbb43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are the consequences of using the Cyclone Separator for improper purposes?\n",
      "\n",
      " Getting response...\n",
      "\n",
      " Answer:\n",
      "According to the text, there are no specific consequences mentioned for using the Cyclone Separator for improper purposes. It only states that \"Guarantee of manufacturer liability cannot be called upon in case of damages to people or objects due to: a. improper Cyclone Separator use;\" which implies that improper use may lead to liability, but it does not specify what those consequences are.\n"
     ]
    }
   ],
   "source": [
    "my_query = \"What are the consequences of using the Cyclone Separator for improper purposes?\"  # CHANGE THIS\n",
    "print(f\"Query: {my_query}\\n\")\n",
    "\n",
    "print(\" Getting response...\")\n",
    "my_result = qa_chain.invoke({\"query\": my_query})\n",
    "my_response = my_result[\"result\"]\n",
    "\n",
    "print(\"\\n Answer:\")\n",
    "print(my_response)\n",
    "\n",
    "# Store for feedback\n",
    "current_query = my_query\n",
    "current_response = my_response\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
